class PatchCoreSWinV2(torch.nn.Module): # uses SWin
    def __init__(
            self,
            l1,
            l2,
            backbone,
            f_coreset:float = 1,    # Fraction rate of training samples
            eps_coreset: float = 0.90, # SparseProjector parameter
            k_nearest: int = 9,        # k parameter for K-NN search
            image_size: int = 224
    ):
        assert f_coreset > 0
        assert eps_coreset > 0
        assert k_nearest > 0
        assert image_size > 0

        super(PatchCoreSWinV2, self).__init__()

        torch.manual_seed(42)
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

        # Hook to extract feature maps
        def hook(module, input, output) -> None:
            """This hook saves the extracted feature map on self.featured."""
            self.features.append(output)

        print(f"[INFO][__init__] Model PatchCore loaded on device: {self.device}")

        # model creation
        self.model = AutoModelForImageClassification.from_pretrained(backbone)
        self.processor = AutoImageProcessor.from_pretrained(backbone)

        self.model.swin.encoder.layers[2].blocks[l1].register_forward_hook(hook)
        self.model.swin.encoder.layers[2].blocks[l1+1].register_forward_hook(hook)
        self.model.swin.encoder.layers[2].blocks[l2].register_forward_hook(hook)
        self.model.swin.encoder.layers[2].blocks[l2+1].register_forward_hook(hook)


        self.model = self.model.to(self.device)

        # Disable gradient computation
        self.model.eval()
        for param in self.model.parameters():
            param.requires_grad = False

        # Parameters
        self.memory_bank = []
        self.f_coreset = f_coreset      # Fraction rate of training samples
        self.eps_coreset = eps_coreset  # SparseProjector parameter
        self.k_nearest = k_nearest      # k parameter for K-NN search
        self.image_size = image_size
        self.threshold = None

    def forward(self, sample: tensor):
        self.features = []
        _ = self.model(sample, return_dict=True)
        return self.features
                   
    def extract_embeddings(self, sample):
        output = self(sample)
        features_maps = torch.cat([ o[0] for o in output ], dim = 2)
        # features_maps = torch.cat([features_maps], 2) # concatenates the feature's levels
        patch = features_maps.squeeze()
        return patch

    def fit(self, train_dataloader: DataLoader,  scale: int=1) -> None:

        tot = len(train_dataloader) // scale
        counter = 0

        for sample, target, filepath, mask in tqdm(train_dataloader, total=tot):
            
            sample_preprocessed = sample.pixel_values[0].to(self.device)    # prepare the sample after
                                                                            # the get_item transformation
            patch = self.extract_embeddings(sample_preprocessed)
            self.memory_bank.append(patch.cpu())

            counter += 1
            if counter > tot:
                break

        self.memory_bank = torch.cat(self.memory_bank, 0) # VStack the patches
        self.memory_bank = self.memory_bank.detach()

        # Coreset subsampling
        if self.f_coreset < 1:
            coreset_idx = get_coreset(
                self.memory_bank,
                l = int(self.f_coreset * self.memory_bank.shape[0]),
                eps = self.eps_coreset
            )
            self.memory_bank = self.memory_bank[coreset_idx]   
        self.memory_bank = self.memory_bank.to("cuda")

    def evaluate(self, test_dataloader: DataLoader, validation_flag = True):
  
        image_preds = []
        image_labels = []
        pixel_preds = []
        pixel_labels = []
        time_list = []

        segm_maps = []

        for sample, label, filepath, mask in tqdm(test_dataloader):
            # TODO GPU
            start_time = time.time()

            image_labels.append(label)
            pixel_labels.extend(mask.flatten().numpy())

            sample_preprocessed = sample.pixel_values[0].to(self.device)    # preprocess after the 
                                                                            # get_image transformation
            score, segm_map = self.predict(sample_preprocessed)  # Anomaly Detection

            end_time = time.time()
            elapsed_time = end_time - start_time
            #print(f"Elapsed time: {elapsed_time:.3f} seconds")
            time_list.append(elapsed_time)

            image_preds.append(score.detach().cpu().numpy())
            pixel_preds.extend(segm_map.flatten().cpu().numpy())
            segm_maps.append(segm_map.flatten().cpu().numpy())

        image_labels = np.stack(image_labels)
        image_preds = np.stack(image_preds)
        
        # Compute ROC AUC for prediction scores
        image_level_rocauc = roc_auc_score(image_labels, image_preds)
        #pixel_level_rocauc = roc_auc_score(pixel_labels, pixel_preds)

        print(f"Test: Image Level ROCAUC: {image_level_rocauc}")
        #print(f"Test: Pixel Level ROCAUC: {pixel_level_rocauc}")


        # calculate image-level ROC AUC score
        if len(np.unique(image_labels))>1:
            fpr, tpr, thresholds = roc_curve(image_labels, image_preds)
            distances = np.sqrt((1-tpr)**2 + fpr**2) # Euclidean distance in a 2D space between points
            best_index = np.argmin(distances)
            initial_score_threshold = thresholds[best_index]
            print('[INFO][evaluate] Image Level ROCAUC: %.3f' % (image_level_rocauc))
            search=10 # -1.5 initial_threshold +1.5
        else:
            initial_score_threshold=0
            search=10 # -10 0 +10
        
        ## Find best threshold value
        optimal_y_hat, optimal_score_f1score, optimal_score_threshold, initial_score_f1score = get_best_threshold(image_labels, image_preds, initial_score_threshold, search)
        print(f"[INFO][evaluate] Initial Score Threshold: {initial_score_threshold:.3f} F1Score: {initial_score_f1score:.3f}")
        print(f"[INFO][evaluate] Optimal Score Threshold: {optimal_score_threshold:.3f} F1Score: {optimal_score_f1score:.3f}")
        print(f"[INFO][evaluate] Average Inference time with batch_size={test_dataloader.batch_size}: {np.mean(time_list):.3f}s")
        if validation_flag:
            self.threshold = optimal_score_threshold
        
        norm_predictions = [(1 if score>self.threshold else 0) for score in image_preds]
        self.cm = confusion_matrix(image_labels, norm_predictions)
        self.prfs = precision_recall_fscore_support(image_labels, norm_predictions, average = 'binary')
        self.ground_truths = image_labels
        self.predictions = image_preds
        self.segm_maps = segm_maps
        self.auc = image_level_rocauc
        
    def predict(self, sample: tensor):

        # Patch extraction
        patch = self.extract_embeddings(sample)

        # Compute maximum distance score s* (equation 6 from the paper)
        distances = torch.cdist(patch, self.memory_bank, p=2.0)         # L2 norm dist btw test patch with each patch of memory bank
        dist_score, dist_score_idxs = torch.min(distances, dim=1)       # Val and index of the distance scores (minimum values of each row in distances)
        s_idx = torch.argmax(dist_score)                                # Index of the anomaly candidate patch
        s_star = torch.max(dist_score)                                  # Maximum distance score s*
        m_test_star = torch.unsqueeze(patch[s_idx], dim=0)              # Anomaly candidate patch
        m_star = self.memory_bank[dist_score_idxs[s_idx]].unsqueeze(0)  # Memory bank patch closest neighbour to m_test_star

        # KNN
        knn_dists = torch.cdist(m_star, self.memory_bank, p=2.0)        # L2 norm dist btw m_star with each patch of memory bank
        _, nn_idxs = knn_dists.topk(k=self.k_nearest, largest=False)    # Values and indexes of the k smallest elements of knn_dists

        # Compute image-level anomaly score s
        m_star_neighbourhood = self.memory_bank[nn_idxs[0, 1:]]
        w_denominator = torch.linalg.norm(m_test_star - m_star_neighbourhood, dim=1)    # Sum over the exp of l2 norm distances btw m_test_star and the m* neighbourhood
        norm = torch.sqrt(torch.tensor(patch.shape[1]))                                 # Softmax normalization trick to prevent exp(norm) from becoming infinite
        w = 1 - (torch.exp(s_star / norm) / torch.sum(torch.exp(w_denominator / norm))) # Equation 7 from the paper
        s = w * s_star

        # # Segmentation map
        fmap_size = (int(np.sqrt(patch.shape[0])), int(np.sqrt(patch.shape[0])))    # Feature map sizes: h, w
        segm_map = dist_score.view(1, 1, *fmap_size)    # Reshape distance scores tensor
        segm_map = torch.nn.functional.interpolate(     # Upscale by bi-linaer interpolation to match the original input resolution
                        segm_map,
                        size=(self.image_size, self.image_size),
                        mode='bilinear'
                    )
        segm_map = gaussian_blur(segm_map.cpu())              # Gaussian blur of kernel width = 4
        
        # debugging purposes
        self.s_idx = s_idx
        self.w = w
        self.s_star = s_star
        self.distances = distances
        self.dist_score = dist_score
        self.dist_score_idxs = dist_score_idxs
        self.target_idx = dist_score_idxs[s_idx]
        self.patch = patch
        return s, segm_map

    def save_memory_bank(self, feature_filepath):
        if not os.path.exists(models_folder):
            model_folder = feature_filepath.split("/")[-2]
            os.makedirs(model_folder)
        # do this after fit
        # Save memory bank
        torch.save(self.memory_bank, feature_filepath)

    def load_memory_bank(self, feature_filepath):
        # Load memory bank
        self.memory_bank = torch.load(feature_filepath)
        self.memory_bank = self.memory_bank.to(self.device)

    ### Cosine stuff

    def predict_cosine(self, sample: tensor):

        # Patch extraction
        patch = self.extract_embeddings(sample)
        self.patch = patch

        # Compute maximum distance score s* (equation 6 from the paper)
        similarities = self.csim(patch, self.memory_bank)         # L2 norm dist btw test patch with each patch of memory bank

        sim_score, sim_score_idxs = torch.max(similarities, dim=1)       # Val and index of the distance scores (minimum values of each row in distances)
        s_idx = torch.argmin(sim_score)                                # Index of the anomaly candidate patch
        s_star = torch.min(sim_score)                                  # Maximum distance score s*
        m_test_star = torch.unsqueeze(patch[s_idx], dim=0)              # Anomaly candidate patch
        m_star = self.memory_bank[sim_score_idxs[s_idx]].unsqueeze(0)  # Memory bank patch closest neighbour to m_test_star

        # KNN
        knn_sims = self.csim(m_star, self.memory_bank)
        _, nn_idxs = knn_sims.topk(k=self.k_nearest, largest=True)    # Values and indexes of the k smallest elements of knn_dists

        # Compute image-level anomaly score s
        m_star_neighbourhood = self.memory_bank[nn_idxs[0, 1:]]
        w_denominator = torch.nn.functional.cosine_similarity(m_test_star, m_star_neighbourhood, dim=1)    # Sum over the exp of l2 norm distances btw m_test_star and the m* neighbourhood
        norm = torch.sqrt(torch.tensor(patch.shape[1]))                                 # Softmax normalization trick to prevent exp(norm) from becoming infinite
        s_star = 1 - s_star
        w_denominator = 1 - w_denominator 
        w = 1 - (torch.exp(s_star / norm) / torch.sum(torch.exp(w_denominator / norm))) # Equation 7 from the paper
        s = w * s_star

        # # Segmentation map
        fmap_size = (int(np.sqrt(patch.shape[0])), int(np.sqrt(patch.shape[0])))    # Feature map sizes: h, w
        segm_map = sim_score.view(1, 1, *fmap_size)    # Reshape distance scores tensor
        segm_map = torch.nn.functional.interpolate(     # Upscale by bi-linaer interpolation to match the original input resolution
                        segm_map,
                        size=(self.image_size, self.image_size),
                        mode='bilinear'
                    )
        segm_map = gaussian_blur(segm_map.cpu())              # Gaussian blur of kernel width = 4
        self.s_idx = s_idx
        self.sim_score = sim_score
        return s, segm_map

    def evaluate_cosine(self, test_dataloader: DataLoader, validation_flag = True):
  
        image_preds = []
        image_labels = []
        pixel_preds = []
        pixel_labels = []
        time_list = []

        segm_maps = []

        for sample, label, filepath, mask in tqdm(test_dataloader):
            # TODO GPU
            start_time = time.time()

            image_labels.append(label)
            pixel_labels.extend(mask.flatten().numpy())

            sample_preprocessed = sample.pixel_values[0].to(self.device)    # preprocess after the 
                                                                            # get_image transformation
            score, segm_map = self.predict_cosine(sample_preprocessed)  # Anomaly Detection

            end_time = time.time()
            elapsed_time = end_time - start_time
            #print(f"Elapsed time: {elapsed_time:.3f} seconds")
            time_list.append(elapsed_time)

            image_preds.append(score.detach().cpu().numpy())
            pixel_preds.extend(segm_map.flatten().cpu().numpy())
            segm_maps.append(segm_map.flatten().cpu().numpy())

        image_labels = np.stack(image_labels)
        image_preds = np.stack(image_preds)
        
        # Compute ROC AUC for prediction scores
        image_level_rocauc = roc_auc_score(image_labels, image_preds)
        #pixel_level_rocauc = roc_auc_score(pixel_labels, pixel_preds)

        print(f"Test: Image Level ROCAUC: {image_level_rocauc}")
        #print(f"Test: Pixel Level ROCAUC: {pixel_level_rocauc}")


        # calculate image-level ROC AUC score
        if len(np.unique(image_labels))>1:
            fpr, tpr, thresholds = roc_curve(image_labels, image_preds)
            distances = np.sqrt((1-tpr)**2 + fpr**2) # Euclidean distance in a 2D space between points
            best_index = np.argmin(distances)
            initial_score_threshold = thresholds[best_index]
            print('[INFO][evaluate] Image Level ROCAUC: %.3f' % (image_level_rocauc))
            search=10 # -1.5 initial_threshold +1.5
        else:
            initial_score_threshold=0
            search=10 # -10 0 +10
        
        ## Find best threshold value
        if validation_flag:
            optimal_y_hat, optimal_score_f1score, optimal_score_threshold, initial_score_f1score = get_best_threshold(image_labels, image_preds, initial_score_threshold, search)
            print(f"[INFO][evaluate] Initial Score Threshold: {initial_score_threshold:.3f} F1Score: {initial_score_f1score:.3f}")
            print(f"[INFO][evaluate] Optimal Score Threshold: {optimal_score_threshold:.3f} F1Score: {optimal_score_f1score:.3f}")
            print(f"[INFO][evaluate] Average Inference time with batch_size={test_dataloader.batch_size}: {np.mean(time_list):.3f}s")
            self.threshold = optimal_score_threshold
        
        norm_predictions = [(1 if score>self.threshold else 0) for score in image_preds]
        self.cm = confusion_matrix(image_labels, norm_predictions)
        self.prfs = precision_recall_fscore_support(image_labels, norm_predictions, average = 'binary')
        self.ground_truths = image_labels
        self.predictions = image_preds
        self.segm_maps = segm_maps
        self.auc = image_level_rocauc

    def csim(self, a, b):
        # a, b must be (1,1536) and (10, 1536)
        # a = model.patch
        # b = model.memory_bank.view(1960,-1)

        a_norm = a / a.norm(dim=1)[:, None]
        b_norm = b / b.norm(dim=1)[:, None]
        res = torch.mm(a_norm, b_norm.transpose(0,1))
        return res
